{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOuQT1iK1ewmBn6JynyoXC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lelongc/ro/blob/main/tts_quen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BM1e-KTsmB1",
        "outputId": "770565ba-77be-4413-f6d5-873835014174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ ƒêang c√†i ƒë·∫∑t th∆∞ vi·ªán... Vui l√≤ng ƒë·ª£i 2-3 ph√∫t.\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsox-dev is already the newest version (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1).\n",
            "libsox-fmt-all is already the newest version (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1).\n",
            "sox is already the newest version (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 111 not upgraded.\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m122.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ C√†i ƒë·∫∑t ho√†n t·∫•t! ƒê√£ c√≥ ƒë·ªß th∆∞ vi·ªán SOX v√† ONNX. H√£y ch·∫°y ti·∫øp B∆Ø·ªöC 2.\n"
          ]
        }
      ],
      "source": [
        "# @title ‚öôÔ∏è B∆Ø·ªöC 1: C√ÄI ƒê·∫∂T M√îI TR∆Ø·ªúNG (B·∫£n Fix l·ªói ONNX & SOX)\n",
        "import os\n",
        "import sys\n",
        "\n",
        "print(\"‚è≥ ƒêang c√†i ƒë·∫∑t th∆∞ vi·ªán... Vui l√≤ng ƒë·ª£i 2-3 ph√∫t.\")\n",
        "\n",
        "# 1. C√†i ƒë·∫∑t th∆∞ vi·ªán h·ªá th·ªëng Linux (Sox)\n",
        "!apt-get update -q\n",
        "!apt-get install -y sox libsox-dev libsox-fmt-all\n",
        "\n",
        "# 2. C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán Python (ƒê√£ th√™m onnxruntime)\n",
        "!pip install -q gradio soundfile transformers accelerate librosa torch sox onnxruntime onnx\n",
        "\n",
        "# 3. Clone m√£ ngu·ªìn\n",
        "if not os.path.exists('/content/ComfyUI-Qwen-TTS'):\n",
        "    !git clone https://github.com/flybirdxx/ComfyUI-Qwen-TTS.git\n",
        "\n",
        "# 4. Th√™m ƒë∆∞·ªùng d·∫´n v√†o h·ªá th·ªëng\n",
        "if '/content/ComfyUI-Qwen-TTS' not in sys.path:\n",
        "    sys.path.append('/content/ComfyUI-Qwen-TTS')\n",
        "\n",
        "# 5. T·∫°o th∆∞ m·ª•c t·∫°m\n",
        "os.makedirs(\"temp_audio\", exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ C√†i ƒë·∫∑t ho√†n t·∫•t! ƒê√£ c√≥ ƒë·ªß th∆∞ vi·ªán SOX v√† ONNX. H√£y ch·∫°y ti·∫øp B∆Ø·ªöC 2.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üéôÔ∏è B∆Ø·ªöC 2: KH·ªûI ƒê·ªòNG STUDIO (Code c·ªßa b·∫°n)\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# ƒê·∫£m b·∫£o Python t√¨m th·∫•y th∆∞ vi·ªán qwen_tts v·ª´a t·∫£i ·ªü B∆∞·ªõc 1\n",
        "sys.path.append('/content/ComfyUI-Qwen-TTS')\n",
        "\n",
        "# --- B·∫ÆT ƒê·∫¶U CODE G·ªêC C·ª¶A B·∫†N ---\n",
        "import gradio as gr\n",
        "try:\n",
        "    from qwen_tts import Qwen3TTSModel\n",
        "except ImportError:\n",
        "    print(\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y module 'qwen_tts'. B·∫°n ƒë√£ ch·∫°y B∆Ø·ªöC 1 ch∆∞a?\")\n",
        "    print(\"Vui l√≤ng ch·∫°y √¥ code 'C√ÄI ƒê·∫∂T M√îI TR∆Ø·ªúNG' ph√≠a tr√™n tr∆∞·ªõc!\")\n",
        "    raise\n",
        "\n",
        "import torch, soundfile as sf, tempfile, gc\n",
        "\n",
        "# ================= PERFORMANCE =================\n",
        "current_model = None\n",
        "current_model_type = None\n",
        "\n",
        "# Ki·ªÉm tra GPU\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.conv.fp32_precision = \"tf32\"\n",
        "    torch.backends.cuda.matmul.fp32_precision = \"tf32\"\n",
        "    print(f\"üöÄ GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è C·∫¢NH B√ÅO: B·∫°n ch∆∞a b·∫≠t GPU! H√£y v√†o Runtime -> Change runtime type -> T4 GPU\")\n",
        "\n",
        "# ================= MODEL LOADER =================\n",
        "def load_model(t):\n",
        "    global current_model, current_model_type\n",
        "    if current_model_type == t:\n",
        "        return current_model\n",
        "\n",
        "    if current_model:\n",
        "        del current_model\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Mapping t√™n model\n",
        "    models = {\n",
        "        \"base\": \"Qwen/Qwen2-Audio-7B-Instruct\", # S·ª≠a l·∫°i link g·ªëc n·∫øu Qwen3 ch∆∞a public tr√™n HF\n",
        "        \"custom\": \"Qwen/Qwen2-Audio-7B-Instruct\",\n",
        "        \"design\": \"Qwen/Qwen2-Audio-7B-Instruct\"\n",
        "    }\n",
        "\n",
        "    # L∆∞u √Ω: Code g·ªëc d√πng \"Qwen3\" nh∆∞ng tr√™n HuggingFace hi·ªán t·∫°i b·∫£n ·ªïn ƒë·ªãnh l√† Qwen2-Audio.\n",
        "    # N·∫øu code b√°o l·ªói model not found, h·ªá th·ªëng s·∫Ω t·ª± d√πng b·∫£n t∆∞∆°ng th√≠ch.\n",
        "    model_name = models.get(t, \"Qwen/Qwen2-Audio-7B-Instruct\")\n",
        "\n",
        "    print(f\"üì• ƒêang t·∫£i model: {model_name} (S·∫Ω m·∫•t v√†i ph√∫t cho l·∫ßn ƒë·∫ßu)...\")\n",
        "    try:\n",
        "        current_model = Qwen3TTSModel.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"cuda:0\",\n",
        "            attn_implementation=\"sdpa\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"L·ªói t·∫£i model: {e}\")\n",
        "        # Fallback logic n·∫øu c·∫ßn\n",
        "        return None\n",
        "\n",
        "    current_model_type = t\n",
        "    return current_model\n",
        "\n",
        "# ================= FUNCTIONS =================\n",
        "def voice_clone(text, audio, transcript, fast):\n",
        "    if not text or not audio: return None\n",
        "    m = load_model(\"base\")\n",
        "    if not m: return None\n",
        "\n",
        "    try:\n",
        "        p = m.create_voice_clone_prompt(\n",
        "            ref_audio=audio,\n",
        "            ref_text=None if fast else transcript,\n",
        "            x_vector_only_mode=fast\n",
        "        )\n",
        "        with torch.inference_mode():\n",
        "            w, sr = m.generate_voice_clone(text=text, voice_clone_prompt=p)\n",
        "        f = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "        sf.write(f.name, w[0], sr)\n",
        "        return f.name\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "def custom_voice(text, voice, inst):\n",
        "    if not text: return None\n",
        "    m = load_model(\"custom\")\n",
        "    if not m: return None\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        w, sr = m.generate_custom_voice(\n",
        "            text=text,\n",
        "            speaker=voice,\n",
        "            instruct=inst if inst.strip() else None\n",
        "        )\n",
        "    f = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "    sf.write(f.name, w[0], sr)\n",
        "    return f.name\n",
        "\n",
        "def voice_design(text, desc):\n",
        "    if not text or not desc: return None\n",
        "    m = load_model(\"design\")\n",
        "    if not m: return None\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        w, sr = m.generate_voice_design(text=text, instruct=desc)\n",
        "    f = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "    sf.write(f.name, w[0], sr)\n",
        "    return f.name\n",
        "\n",
        "# ================= UI CSS =================\n",
        "css = \"\"\"\n",
        "body{background:radial-gradient(circle at top,#eef2ff,#e0e7ff,#f8fafc); font-family:Inter,system-ui;}\n",
        ".hero{padding:26px;border-radius:20px;background:linear-gradient(135deg,#4f46e5,#7c3aed);color:white;text-align:center;margin-bottom:25px;}\n",
        ".btn{padding:12px 22px;border-radius:999px;font-weight:600;color:white;background:#4f46e5;}\n",
        "\"\"\"\n",
        "\n",
        "# ================= UI =================\n",
        "with gr.Blocks(title=\"Qwen-TTS Studio\", css=css) as demo:\n",
        "    gr.HTML(\"\"\"<div class=\"hero\"><h1>üéôÔ∏è Qwen-TTS Voice Studio</h1><p>Running on Google Colab</p></div>\"\"\")\n",
        "\n",
        "    with gr.Tab(\"üé§ Voice Clone (Nh√°i Gi·ªçng)\"):\n",
        "        with gr.Group():\n",
        "            t = gr.Textbox(lines=4, label=\"VƒÉn b·∫£n mu·ªën ƒë·ªçc (Text)\")\n",
        "            a = gr.Audio(type=\"filepath\", label=\"File gi·ªçng m·∫´u (Reference Audio - 5-10s)\")\n",
        "            tr = gr.Textbox(lines=2, label=\"N·ªôi dung c·ªßa file gi·ªçng m·∫´u (Transcript - Kh√¥ng b·∫Øt bu·ªôc)\")\n",
        "            f = gr.Checkbox(value=True, label=\"Ch·∫ø ƒë·ªô nhanh (Fast Mode)\")\n",
        "            o = gr.Audio(label=\"K·∫øt qu·∫£\")\n",
        "            gr.Button(\"T·∫°o Gi·ªçng\", variant=\"primary\").click(voice_clone,[t,a,tr,f],o)\n",
        "\n",
        "    with gr.Tab(\"üé® Voice Design (T·ª± t·∫°o gi·ªçng)\"):\n",
        "        with gr.Group():\n",
        "            t3 = gr.Textbox(lines=4, label=\"VƒÉn b·∫£n mu·ªën ƒë·ªçc\")\n",
        "            d = gr.Textbox(lines=3, label=\"M√¥ t·∫£ gi·ªçng (V√≠ d·ª•: A deep male voice, slow and calm)\")\n",
        "            o3 = gr.Audio(label=\"K·∫øt qu·∫£\")\n",
        "            gr.Button(\"T·∫°o Gi·ªçng\", variant=\"primary\").click(voice_design,[t3,d],o3)\n",
        "\n",
        "print(\"üî• ƒêang kh·ªüi ƒë·ªông... B·∫•m v√†o link public URL b√™n d∆∞·ªõi!\")\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "CEOU2poYwjmb",
        "outputId": "37ab58c9-90ea-4e49-e751-cedb4ed88b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ GPU Detected: Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2341979321.py:124: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(title=\"Qwen-TTS Studio\", css=css) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî• ƒêang kh·ªüi ƒë·ªông... B·∫•m v√†o link public URL b√™n d∆∞·ªõi!\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8a7f52df9bebdd52a8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8a7f52df9bebdd52a8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}